# 基于隐马尔科夫模型HMM的中文分词

[基于词典匹配的中文分词](https://mp.weixin.qq.com/s?__biz=MzUyNTEwMjM4NQ==&mid=2247483698&idx=1&sn=87d2d457604d955aa913e8b857f75485&chksm=fa227d6ccd55f47abc0b807e8b57e2e234cecddad99003846f95c49951098c95be55e1e00998&token=2042160806&lang=zh_CN#rd)模型相对简单，在实际应用中最大的问题是不能发现词典中没有的新词；从而在语义分析时效果不佳，如在基于词语召回的搜索引擎里不能精准召回相关文档。

如，

> 人艰不拆

不在词典中，最终会被切分成4个单字，当用户搜索这个词语时，需要从4个单字分别召回，既非常不精准，也大幅增加了计算量。

# 1. 使用效果

分词使用效果都一样。

输入语句：

> 

得到分词结果：

> 

# 2. 使用过程

不像基于词典匹配的分词，只需要加载词典。

包括HMM在内，大部分分词模型都将分词看做序列标注任务。

1. 对已经标注好分词的训练数据加上4元组标注['**B**egin', '**M**iddle', '**E**nd', '**S**ingle']，分别表示一个词语的开始、中间、结尾以及单字词语。

2. 模型训练：用监督学习得到模型参数，在HMM里就是统计频度。保存模型。

3. 模型预测：加载模型，对测试语句进行序列标注，当得到标注为E或者S，则在该字符处切割。

# 3. HMM模型介绍

HMM是Hidden Markov Model的缩写，是一种生成式的概率图模型。

概率图模型表示为：

> 观测变量：${x_1, x_2, ..., x_N}$，$x_i$在中文分词任务里对应输入序列的一个字符$o_j$，$x_i \in \{o_1, o_2, ..., o_V\}$, $V$是字符的个数。

> 状态变量：${y_1, y_2, ..., y_N}$，$y_i$在中文分词任务里对应隐藏的状态['B', 'M', 'E', 'S']之一。$y_i \in \{s_1, s_2, ..., s_S\}$，$S$是状态的个数。

<img src="">

HMM包括三组参数:$(\pi, T, E)$： 

> $\pi_{S}: \pi_i = p(y_1 = i)$是状态的**初始概率分布**；

> $T_{S*S}: T(i, j)=p(y_{t+1}=j|y_t=i)$是从$t$时刻的状态$i$，到$t+1$时刻的状态$j$的**转移概率**；

> $E_{S * V}: E(s, o)=p(x_t = o | y_t = s)$是在时刻$t$，状态$s$到观测值$o$的**发射概率**。

## 3.1 HMM的假设

TODO

基于HMM的中文分词，就是用给定已经分好词的训练语料，学习三元组参数；对于测试数据，用三元组数据寻找最可能的标注序列。

# 4. 模型训练

根据伯努利大数定律，当试验次数足够多的时候，事件发生的频率无穷接近于该事件发生的概率，我们通过统计事件的频率来估计HMM的参数。

假设总的样本个数为$M$。

> $\pi_i = \frac{count(y_1=i)}{M}$
>
> 

> $T(i, j) = \frac{count(y_t=i, y_{t+1}=j)}{count(y_t=i)}$
>
> 

> $E(s, o) = \frac{count(y_t=s, x_t=o)}{count(y_t=s)}$
>
> 

# 5. 模型预测

Viterbi.

## 5.1 序列最大概率递推

$y^* = \arg\max_{y_1, y_2, ..., y_N} p(y_1, y_2, ..., y_N | x_1, x_2, ..., x_N; \theta)$

用$\sigma_t(i)$表示状态序列$y_1, y_2, ..., y_t$在$y_t=i$的情况下的的最大概率，即经过第$t$步节点值为$i$的最优路径的概率，

> $\sigma_t(i) = \max_{y_1,y_2,...,y_{t-1}} p(y_t=i,y_1,y_2,...,y_{t-1},x_1,x_2,...,x_t|\theta)$

$\sigma_{N*S}$的递推表达式为，

> $\sigma_{t+1}(j)=max_{i}\sigma_t(i)T(i, j)E(j, x_{t+1})$

起始条件是，

> $\sigma_1(i) = \pi_i E(i, x_1)$

## 5.2 最优状态节点递推

$N$时刻的最优状态节点为：

> $y_N^*=\arg\max_s \sigma_N(s)$

对于序列$y_1, y_2, ..., y_t$，如果在$t$时刻的最优状态节点满足$y_t^*=j$，则$t-1$时刻的最优状态节点满足：

> $y_{t-1}^* = \arg\max_{i} \sigma_{t-1}(i) T(i, j)$

实现的时候，用一个临时变量$\phi(t, )$保存$\sigma_{t-1}(i)T(i,j)$

# 6. 模型评估


1. 使用HMM对测试数据进行序列标注，遇到标记为'S'或者'E'则进行切分。

2. 对分词结果与基准分词进行比对。

# 7. 总结

# 8. 参考资料

1. 《自然语言处理入门》，何晗。

2. 《统计学习方法》，李航。